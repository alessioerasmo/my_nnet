{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function\n",
    "An activation function is given as a class with two static methods returning function evaluation on a certain point and derivative evaluation on a certain point\n",
    "#### examples:\n",
    "those are some implementations of smooth activation functions\n",
    "##### $sigmoid$ smooth function between 1 and 0\n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$\n",
    "$$\\sigma'(x)=\\frac{e^x}{(1+e^{x})^2}$$\n",
    "##### $custom tanh$ smooth function between 1 and 0, \"sharper\" than sigmoid\n",
    "$$\\rho(x)= \\frac{tanh(x)}{2} + \\frac{1}{2}$$\n",
    "$$\\sigma'(x)=\\frac{sech^2(x)}{2}$$\n",
    "One can define its own function, as long as it is derivable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import e as e\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class sigmoid:\n",
    "    def get(num):\n",
    "        return 1/(1+ math.pow(math.e, -num))\n",
    "    \n",
    "    def get_derivate(num):\n",
    "        return math.pow(e,num)/math.pow( (math.pow(e, num) + 1) ,2)\n",
    "\n",
    "class softplus:\n",
    "    def get(num):\n",
    "        return math.log((1+math.pow(e,num)),e)\n",
    "    def get_derivate(num):\n",
    "        return sigmoid.get(num)\n",
    "\n",
    "class identity:\n",
    "    def get(num):\n",
    "        return num\n",
    "    \n",
    "    def get_derivate(num):\n",
    "        return 1\n",
    "\n",
    "class my_tanh:\n",
    "    def get(num):\n",
    "        return math.tanh(num)/2 + 1/2\n",
    "\n",
    "    def get_derivate(num):\n",
    "        return math.pow((1/math.cosh(num)), 2)/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class perceptron:\n",
    "\n",
    "    def __init__(self, n_inputs, activation=sigmoid, init_weights=\"random\") -> None:\n",
    "        self.activation = activation.get\n",
    "        self.activation_derivative = activation.get_derivate\n",
    "        self.bias = random.random()\n",
    "\n",
    "        if (init_weights == \"random\"):\n",
    "            self.weights = np.random.random(n_inputs)\n",
    "        elif (init_weights == \"ones\"):\n",
    "            self.weights = np.zeros(n_inputs)\n",
    "        elif (init_weights == \"zeros\"):\n",
    "            self.weights = np.ones(n_inputs)\n",
    "        else:\n",
    "            self.weights = np.random.random(n_inputs)\n",
    "\n",
    "    def weighted_sum(self, sample):\n",
    "        return np.sum(np.array(sample) * self.weights) + self.bias\n",
    "\n",
    "    def output(self,sample):\n",
    "        assert len(sample)== len(self.weights)\n",
    "        return self.activation(self.weighted_sum(sample))\n",
    "\n",
    "    def get_error(self, sample, target):\n",
    "        return np.linalg.norm(self.output(sample)-target)/2\n",
    "\n",
    "    def GD_update_weights(self, sample, target, epsilon=1 ):\n",
    "        val = self.output(sample)\n",
    "        delta_val = -(val-target) * self.activation_derivative( self.weighted_sum(sample) ) \n",
    "        delta = np.array([ delta_val * sample[i]  for i in range(len(self.weights))])\n",
    "        self.weights = self.weights + epsilon*delta\n",
    "        self.bias += epsilon*delta_val\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning \"AND\" function\n",
    "We give to a perceptron the and function's table of truth as dataset\n",
    " \n",
    "| A   | B   | A $\\land$ B |\n",
    "| --- | --- | ------- |\n",
    "| 0   | 0   |   0     |\n",
    "| 0   | 1   |   0     |\n",
    "| 1   | 0   |   0     |\n",
    "| 1   | 1   |   1     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  predicted 0 ( 0.20146537956286173 )\n",
      "[0 1]  predicted 0 ( 0.3826839229808979 )\n",
      "[1 0]  predicted 0 ( 0.4289922288076337 )\n",
      "[1 1]  predicted 1 ( 0.7509472381870473 )\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,0,0,1])\n",
    "\n",
    "epochs = 10\n",
    "epsilon = 1\n",
    "\n",
    "p = perceptron(2, activation=softplus)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        p.GD_update_weights(sample=X[i], target=y[i], epsilon=epsilon)\n",
    "\n",
    "def treshold(x): \n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], \" predicted\", treshold(p.output(X[i])), \"(\",p.output(X[i]),\")\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Learning \"OR\" function\n",
    "We give to a perceptron the or function's table of truth as dataset\n",
    " \n",
    "| A   | B   | A $\\lor$ B |\n",
    "| --- | --- | ------- |\n",
    "| 0   | 0   |   0     |\n",
    "| 0   | 1   |   1     |\n",
    "| 1   | 0   |   1     |\n",
    "| 1   | 1   |   1     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  predicted 0 ( 0.48274681566496364 )\n",
      "[0 1]  predicted 1 ( 0.8133467364888467 )\n",
      "[1 0]  predicted 1 ( 0.7950309581271464 )\n",
      "[1 1]  predicted 1 ( 0.9476715149621044 )\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,1])\n",
    "\n",
    "epochs = 10\n",
    "epsilon = 2\n",
    "\n",
    "p = perceptron(2, activation=sigmoid)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        p.GD_update_weights(sample=X[i], target=y[i], epsilon=epsilon)\n",
    "\n",
    "def treshold(x): \n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], \" predicted\", treshold(p.output(X[i])), \"(\",p.output(X[i]),\")\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
