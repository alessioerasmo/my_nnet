{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function\n",
    "An activation function is given as a class with two static methods returning function evaluation on a certain point and derivative evaluation on a certain point \n",
    "\n",
    "#### example: $sigmoid$\n",
    "\n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-x}}$$\n",
    "$$\\sigma'(x)=\\frac{e^x}{(1+e^{x})^2}$$\n",
    "\n",
    "One can define its own function, as long as it is derivable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import e as e\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class sigmoid:\n",
    "    def get(num):\n",
    "        return 1/(1+ math.pow(math.e, -num))\n",
    "    \n",
    "    def get_derivate(num):\n",
    "        return math.pow(e,num)/math.pow( (math.pow(e, num) + 1) ,2)\n",
    "\n",
    "class identity:\n",
    "    def get(num):\n",
    "        return num\n",
    "    \n",
    "    def get_derivate(num):\n",
    "        return 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class perceptron:\n",
    "\n",
    "    def __init__(self, n_inputs, activation=sigmoid) -> None:\n",
    "        self.activation = activation.get\n",
    "        self.activation_derivative = activation.get_derivate\n",
    "        self.bias = random.random()\n",
    "        self.weights = np.array([ random.random() for i in range(n_inputs)])\n",
    "\n",
    "    def weighted_sum(self, sample):\n",
    "        return np.sum(np.array(sample) * self.weights) + self.bias\n",
    "\n",
    "    def output(self,sample):\n",
    "        assert len(sample)== len(self.weights)\n",
    "        return self.activation(self.weighted_sum(sample))\n",
    "\n",
    "    def get_error(self, sample, target):\n",
    "        return np.linalg.norm(self.output(sample)-target)/2\n",
    "\n",
    "    def GD_update_weights(self, sample, target, epsilon=1 ):\n",
    "        val = self.output(sample)\n",
    "        delta_val = -(val-target) * self.activation_derivative( self.weighted_sum(sample) ) \n",
    "        delta = np.array([ delta_val * sample[i]  for i in range(len(self.weights))])\n",
    "        self.weights = self.weights + epsilon*delta\n",
    "        self.bias += epsilon*delta_val\n",
    "        print(\"\\nweights :\", self.weights, \"\\nbias:\", self.bias)\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "weights : [0.20919632 0.13650598] \n",
      "bias: -0.3816149882079438\n",
      "\n",
      "weights : [0.20919632 0.626724  ] \n",
      "bias: 0.10860303360754497\n",
      "\n",
      "weights : [-0.42640239  0.626724  ] \n",
      "bias: -0.526995670290624\n",
      "\n",
      "weights : [2.22694573 3.28007211] \n",
      "bias: 2.1263524431725065\n",
      "\n",
      "weights : [2.22694573 3.28007211] \n",
      "bias: -2.1263524431725065\n",
      "\n",
      "weights : [2.22694573 0.97263277] \n",
      "bias: -4.433791781985131\n",
      "\n",
      "weights : [6.64063784 0.97263277] \n",
      "bias: -0.020099673827870923\n",
      "\n",
      "weights : [ -6.54570404 -12.2137091 ] \n",
      "bias: -13.206441545832039\n",
      "\n",
      "weights : [ -6.54570404 -12.2137091 ] \n",
      "bias: 13.206441545832039\n",
      "\n",
      "weights : [ -6.54570404 -14.19917399] \n",
      "bias: 11.220976650643909\n",
      "\n",
      "weights : [-15.89624927 -14.19917399] \n",
      "bias: 1.8704314212369066\n",
      "\n",
      "weights : [42.55373441 44.25080968] \n",
      "bias: 60.32041509631012\n",
      "\n",
      "weights : [42.55373441 44.25080968] \n",
      "bias: -60.32041509631012\n",
      "\n",
      "weights : [42.55373441 76.39002051] \n",
      "bias: -28.181204266984103\n",
      "\n",
      "weights : [13.80867412 76.39002051] \n",
      "bias: -56.92626455246751\n",
      "\n",
      "weights : [-50.73618604  11.84516035] \n",
      "bias: -121.47112471796356\n",
      "\n",
      "weights : [-50.73618604  11.84516035] \n",
      "bias: 121.47112471796356\n",
      "\n",
      "weights : [ -50.73618604 -254.78740978] \n",
      "bias: -145.16144540891776\n",
      "\n",
      "weights : [ 341.05907686 -254.78740978] \n",
      "bias: 246.63381749142502\n",
      "\n",
      "weights : [-322.75189228 -918.59837892] \n",
      "bias: -417.17715164679487\n",
      "[0 0]  predicted 0 ( -417.17715164679487 )\n",
      "[0 1]  predicted 0 ( -1335.775530566419 )\n",
      "[1 0]  predicted 0 ( -739.9290439259256 )\n",
      "[1 1]  predicted 0 ( -1658.5274228455496 )\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,0,0,1])\n",
    "\n",
    "epochs = 5\n",
    "epsilon = 2\n",
    "\n",
    "p = perceptron(2, activation=identity)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        p.GD_update_weights(sample=X[i], target=y[i], epsilon=epsilon)\n",
    "\n",
    "def treshold(x): \n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], \" predicted\", treshold(p.output(X[i])), \"(\",p.output(X[i]),\")\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0]  predicted 0 ( 0.43640849899956097 )\n",
      "[0 1]  predicted 1 ( 0.8043740318556686 )\n",
      "[1 0]  predicted 1 ( 0.8126548127127583 )\n",
      "[1 1]  predicted 1 ( 0.9583920004045619 )\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,1])\n",
    "\n",
    "epochs = 10\n",
    "epsilon = 2\n",
    "\n",
    "p = perceptron(2)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        p.GD_update_weights(sample=X[i], target=y[i], epsilon=epsilon)\n",
    "\n",
    "def treshold(x): \n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], \" predicted\", treshold(p.output(X[i])), \"(\",p.output(X[i]),\")\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0.]\n",
      "[    0.         13549.94418465]\n",
      "[-0.00000000e+00 -8.12993941e+09]\n",
      "[0.00000000e+00 8.53642012e+15]\n",
      "[-0.00000000e+00 -1.47964469e+22]\n",
      "[0.00000000e+00 3.88406504e+28]\n",
      "[-0.00000000e+00 -1.44487164e+35]\n",
      "[0.00000000e+00 7.24843743e+41]\n",
      "[-0.00000000e+00 -4.72183829e+48]\n",
      "[0.0000000e+00 3.8778091e+55]\n",
      "[-4.30867619e+59 -0.00000000e+00]\n",
      "[8.61692151e+64 8.61692151e+64]\n",
      "[-3.44675999e+70 -6.89351998e+70]\n",
      "[2.75740368e+76 8.27221105e+76]\n",
      "[-3.86036171e+82 -1.54414468e+83]\n",
      "[8.49279107e+88 4.24639554e+89]\n",
      "[-2.71769214e+95 -1.63061528e+96]\n",
      "[1.19578423e+102 8.37048959e+102]\n",
      "[-6.93554716e+108 -5.54843773e+109]\n",
      "[5.13230412e+115 4.61907371e+116]\n",
      "[-3.07938206e+121 -0.00000000e+000]\n",
      "[1.53967871e+127 7.69839355e+126]\n",
      "[-1.07777356e+133 -1.07777356e+133]\n",
      "[1.18554968e+139 1.77832452e+139]\n",
      "[-2.01543306e+145 -4.03086612e+145]\n",
      "[5.03858027e+151 1.25964507e+152]\n",
      "[-1.76350251e+158 -5.29050753e+158]\n",
      "[8.28845979e+164 2.90096093e+165]\n",
      "[-5.05595954e+171 -2.02238381e+172]\n",
      "[3.89308828e+178 1.75188973e+179]\n",
      "[-4.08774216e+184 -0.00000000e+000]\n",
      "[4.08773282e+190 1.36257761e+190]\n",
      "[-4.90527529e+196 -3.27018353e+196]\n",
      "[7.84843516e+202 7.84843516e+202]\n",
      "[-1.72665485e+209 -2.30220647e+209]\n",
      "[5.17996259e+215 8.63327099e+215]\n",
      "[-2.07198445e+222 -4.14396890e+222]\n",
      "[1.07743168e+229 2.51400726e+229]\n",
      "[-7.11104789e+235 -1.89627944e+236]\n",
      "[5.83105849e+242 1.74931755e+243]\n",
      "[-1.01071668e+249 -0.00000000e+000]\n",
      "[1.71821665e+255 4.29554162e+254]\n",
      "[-3.26460991e+261 -1.63230496e+261]\n",
      "[7.50859936e+267 5.63144952e+267]\n",
      "[-2.177493e+274 -2.177493e+274]\n",
      "[8.05672169e+280 1.00709021e+281]\n",
      "[-3.78665830e+287 -5.67998745e+287]\n",
      "[2.23412798e+294 3.90972396e+294]\n",
      "[-1.63091318e+301 -3.26182636e+301]\n",
      "[1.45151255e+308             inf]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan]\n",
      "[nan nan] nan\n",
      "[0, 0]  predicted nan\n",
      "[0, 1]  predicted nan\n",
      "[0, 2]  predicted nan\n",
      "[0, 3]  predicted nan\n",
      "[0, 4]  predicted nan\n",
      "[0, 5]  predicted nan\n",
      "[0, 6]  predicted nan\n",
      "[0, 7]  predicted nan\n",
      "[0, 8]  predicted nan\n",
      "[0, 9]  predicted nan\n",
      "[1, 0]  predicted nan\n",
      "[1, 1]  predicted nan\n",
      "[1, 2]  predicted nan\n",
      "[1, 3]  predicted nan\n",
      "[1, 4]  predicted nan\n",
      "[1, 5]  predicted nan\n",
      "[1, 6]  predicted nan\n",
      "[1, 7]  predicted nan\n",
      "[1, 8]  predicted nan\n",
      "[1, 9]  predicted nan\n",
      "[2, 0]  predicted nan\n",
      "[2, 1]  predicted nan\n",
      "[2, 2]  predicted nan\n",
      "[2, 3]  predicted nan\n",
      "[2, 4]  predicted nan\n",
      "[2, 5]  predicted nan\n",
      "[2, 6]  predicted nan\n",
      "[2, 7]  predicted nan\n",
      "[2, 8]  predicted nan\n",
      "[2, 9]  predicted nan\n",
      "[3, 0]  predicted nan\n",
      "[3, 1]  predicted nan\n",
      "[3, 2]  predicted nan\n",
      "[3, 3]  predicted nan\n",
      "[3, 4]  predicted nan\n",
      "[3, 5]  predicted nan\n",
      "[3, 6]  predicted nan\n",
      "[3, 7]  predicted nan\n",
      "[3, 8]  predicted nan\n",
      "[3, 9]  predicted nan\n",
      "[4, 0]  predicted nan\n",
      "[4, 1]  predicted nan\n",
      "[4, 2]  predicted nan\n",
      "[4, 3]  predicted nan\n",
      "[4, 4]  predicted nan\n",
      "[4, 5]  predicted nan\n",
      "[4, 6]  predicted nan\n",
      "[4, 7]  predicted nan\n",
      "[4, 8]  predicted nan\n",
      "[4, 9]  predicted nan\n",
      "[5, 0]  predicted nan\n",
      "[5, 1]  predicted nan\n",
      "[5, 2]  predicted nan\n",
      "[5, 3]  predicted nan\n",
      "[5, 4]  predicted nan\n",
      "[5, 5]  predicted nan\n",
      "[5, 6]  predicted nan\n",
      "[5, 7]  predicted nan\n",
      "[5, 8]  predicted nan\n",
      "[5, 9]  predicted nan\n",
      "[6, 0]  predicted nan\n",
      "[6, 1]  predicted nan\n",
      "[6, 2]  predicted nan\n",
      "[6, 3]  predicted nan\n",
      "[6, 4]  predicted nan\n",
      "[6, 5]  predicted nan\n",
      "[6, 6]  predicted nan\n",
      "[6, 7]  predicted nan\n",
      "[6, 8]  predicted nan\n",
      "[6, 9]  predicted nan\n",
      "[7, 0]  predicted nan\n",
      "[7, 1]  predicted nan\n",
      "[7, 2]  predicted nan\n",
      "[7, 3]  predicted nan\n",
      "[7, 4]  predicted nan\n",
      "[7, 5]  predicted nan\n",
      "[7, 6]  predicted nan\n",
      "[7, 7]  predicted nan\n",
      "[7, 8]  predicted nan\n",
      "[7, 9]  predicted nan\n",
      "[8, 0]  predicted nan\n",
      "[8, 1]  predicted nan\n",
      "[8, 2]  predicted nan\n",
      "[8, 3]  predicted nan\n",
      "[8, 4]  predicted nan\n",
      "[8, 5]  predicted nan\n",
      "[8, 6]  predicted nan\n",
      "[8, 7]  predicted nan\n",
      "[8, 8]  predicted nan\n",
      "[8, 9]  predicted nan\n",
      "[9, 0]  predicted nan\n",
      "[9, 1]  predicted nan\n",
      "[9, 2]  predicted nan\n",
      "[9, 3]  predicted nan\n",
      "[9, 4]  predicted nan\n",
      "[9, 5]  predicted nan\n",
      "[9, 6]  predicted nan\n",
      "[9, 7]  predicted nan\n",
      "[9, 8]  predicted nan\n",
      "[9, 9]  predicted nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_1860\\2061828833.py:25: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  delta = np.array([ delta_val * sample[i]  for i in range(len(self.weights))])\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_1860\\2061828833.py:26: RuntimeWarning: overflow encountered in multiply\n",
      "  self.weights = self.weights + epsilon*delta\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_1860\\2061828833.py:27: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  self.bias += epsilon*delta_val\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_1860\\2061828833.py:13: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sum(np.array(sample) * self.weights) + self.bias\n"
     ]
    }
   ],
   "source": [
    "def f(x,y):\n",
    "    return -2*x+3*y\n",
    "\n",
    "X = [ [i,j] for i in range(10) for j in range(10)]\n",
    "y = [f(x[0], x[1]) for x in X]\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "epsilon = 1e05\n",
    "\n",
    "p = perceptron(2, activation=identity)\n",
    "\n",
    "for i in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "        p.GD_update_weights(sample=X[i], target=y[i], epsilon=epsilon)\n",
    "\n",
    "print(p.weights, p.bias)\n",
    "\n",
    "for i in range(len(X)):\n",
    "    print(X[i], \" predicted\", p.output(X[i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.activation_derivative(97382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
